
- main_args params:
    - arch: ViT_B_16
    - batch_size: 128
    - num_samples: 1024

- weight params:
    - scheme: AbsMaxQuantizer
    - bit_width: 4
    - per_channel: True

- activation params:
    - scheme: MovAvgAbsMaxQuantizer
    - bit_width: 8
    - idadd_bit_width: 18
    - per_channel: False
    - momentum: 0.95
    - batches: 4
    - Identity addition : INT16 (The input of each LayerNorm)

- softmax params:
    - bit_width: 17
    - left_shift_for_exp: 15
    - act_quant_bit_width: 4
    - Activation of Softmax(Q@K/d_K) (attn_map) : UINT8

- layer_norm params:
    - using: True

- gelu params:
    - sigmoid_bit_width: 8
    - left_shift_for_exp: 23
    - act_quant_bit_width: 8

IntSoftMax | output bit : 17, exp Lshift : 15
Int log_sqrt_2 quantizer | output bit : 4
IntGELU    | sigmoid bit: 8, exp Lshift: 23
IntSoftMax | output bit : 17, exp Lshift : 15
Int log_sqrt_2 quantizer | output bit : 4
IntGELU    | sigmoid bit: 8, exp Lshift: 23
IntSoftMax | output bit : 17, exp Lshift : 15
Int log_sqrt_2 quantizer | output bit : 4
IntGELU    | sigmoid bit: 8, exp Lshift: 23
IntSoftMax | output bit : 17, exp Lshift : 15
Int log_sqrt_2 quantizer | output bit : 4
IntGELU    | sigmoid bit: 8, exp Lshift: 23
IntSoftMax | output bit : 17, exp Lshift : 15
Int log_sqrt_2 quantizer | output bit : 4
IntGELU    | sigmoid bit: 8, exp Lshift: 23
IntSoftMax | output bit : 17, exp Lshift : 15
Int log_sqrt_2 quantizer | output bit : 4
IntGELU    | sigmoid bit: 8, exp Lshift: 23
IntSoftMax | output bit : 17, exp Lshift : 15
Int log_sqrt_2 quantizer | output bit : 4
IntGELU    | sigmoid bit: 8, exp Lshift: 23
IntSoftMax | output bit : 17, exp Lshift : 15
Int log_sqrt_2 quantizer | output bit : 4
IntGELU    | sigmoid bit: 8, exp Lshift: 23
IntSoftMax | output bit : 17, exp Lshift : 15
Int log_sqrt_2 quantizer | output bit : 4
IntGELU    | sigmoid bit: 8, exp Lshift: 23
IntSoftMax | output bit : 17, exp Lshift : 15
Int log_sqrt_2 quantizer | output bit : 4
IntGELU    | sigmoid bit: 8, exp Lshift: 23
IntSoftMax | output bit : 17, exp Lshift : 15
Int log_sqrt_2 quantizer | output bit : 4
IntGELU    | sigmoid bit: 8, exp Lshift: 23
IntSoftMax | output bit : 17, exp Lshift : 15
Int log_sqrt_2 quantizer | output bit : 4
IntGELU    | sigmoid bit: 8, exp Lshift: 23
Training model for calibration...
Score : 1010186.9375
best bias : tensor([46.], device='cuda:0'), best k : 1

Score : 1186759.125
best bias : tensor([46.], device='cuda:0'), best k : 1

Score : 2297704.75
best bias : tensor([46.], device='cuda:0'), best k : 1

Score : 2116255.25
best bias : tensor([46.], device='cuda:0'), best k : 1

Score : 1674469.5
best bias : tensor([46.], device='cuda:0'), best k : 1

Score : 1266957.5
best bias : tensor([46.], device='cuda:0'), best k : 1

Score : 1522662.75
best bias : tensor([46.], device='cuda:0'), best k : 1

Score : 1314503.0
best bias : tensor([46.], device='cuda:0'), best k : 1

Score : 1192720.625
best bias : tensor([46.], device='cuda:0'), best k : 1

Score : 1037677.375
best bias : tensor([46.], device='cuda:0'), best k : 1

Score : 879319.1875
best bias : tensor([46.], device='cuda:0'), best k : 1

Score : 981132.0
best bias : tensor([46.], device='cuda:0'), best k : 1


    Quantized model Evaluation accuracy on 50000 images, 72.072%, 90.564%
Total time: 783.83 sec
